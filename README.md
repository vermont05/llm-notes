# llm-notes

https://www.reddit.com/r/LocalLLaMA/comments/1men28l/guide_the_simple_selfhosted_ai_coding_that_just/

Clarity: You need both an LLM and a Text Embedding
Ordering issues: Start both models and `Start Server` before turning on MCP Plugin
Size issues: Roo complains unless the models size is increased to 32k
Heat issues: Analyzing codebase is quite intensive. Turn on fan.
